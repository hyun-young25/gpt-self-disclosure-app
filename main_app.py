import streamlit as st
import pandas as pd
import datetime
from gtts import gTTS
from openai import OpenAI
import uuid
import os
import speech_recognition as sr

client = OpenAI(api_key=st.secrets["openai"]["api_key"])

st.set_page_config(page_title="ê°ì • ì¤‘ì‹¬ ìê¸°ê°œë°© ì‹¤í—˜", layout="centered")
st.title("ğŸ¤ ê°ì • ì¤‘ì‹¬ ìê¸°ê°œë°© ì‹¤í—˜")
st.markdown("ë¨¼ì € ì¸í„°í˜ì´ìŠ¤ ìœ í˜•ì„ ì„ íƒí•œ í›„, 3ê°œì˜ ì§ˆë¬¸ì„ ì„ íƒí•˜ê³  GPTì™€ ìƒí˜¸ì‘ìš©í•´ì£¼ì„¸ìš”.")

# 1. ì¸í„°í˜ì´ìŠ¤ ì„ íƒ
interface = st.radio("GPTì™€ì˜ ëŒ€í™” ë°©ì‹ ì„ íƒ", ("ğŸ“ í…ìŠ¤íŠ¸ ì¸í„°í˜ì´ìŠ¤", "ğŸ™ï¸ ìŒì„± ì¸í„°í˜ì´ìŠ¤"))

# 2. ê³µí†µ ì§ˆë¬¸
questions = [
    "1. ìš”ì¦˜ ë‹¹ì‹ ì´ ìì£¼ í•˜ëŠ” ê³ ë¯¼ì€ ë¬´ì—‡ì¸ê°€ìš”?",
    "2. ìµœê·¼ ê°€ì¥ í˜ë“¤ì—ˆë˜ ì¼ì´ ìˆë‹¤ë©´ ë¬´ì—‡ì¸ê°€ìš”?",
    "3. ëˆ„êµ°ê°€ì—ê²Œ í„¸ì–´ë†“ì§€ ëª»í–ˆë˜ ì´ì•¼ê¸°ê°€ ìˆë‹¤ë©´ ì–´ë–¤ ì´ì•¼ê¸°ì¸ê°€ìš”?",
    "4. ì–´ë–¤ ìƒí™©ì—ì„œ ì™¸ë¡œì›€ì„ ëŠë¼ë‚˜ìš”?",
    "5. ë‹¹ì‹ ì—ê²Œ ì¤‘ìš”í•œ ì¸ê°„ê´€ê³„ë‚˜ ê°ì • ê²½í—˜ì€ ì–´ë–¤ ê²ƒì´ ìˆë‚˜ìš”?",
    "6. ì§€ê¸ˆ ëˆ„êµ°ê°€ì—ê²Œ ì§„ì‹¬ìœ¼ë¡œ ì „í•˜ê³  ì‹¶ì€ ë§ì´ ìˆë‹¤ë©´ ë¬´ì—‡ì¸ê°€ìš”?"
]
selected_questions = st.multiselect("ğŸ§  ì•„ë˜ ì§ˆë¬¸ ì¤‘ 3ê°œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”", questions, max_selections=3)

# ë°ì´í„° ì €ì¥ìš©
dialogue_data = []

# GPT ì‘ë‹µ í•¨ìˆ˜
def ask_gpt(user_input):
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "ë„ˆëŠ” ë”°ëœ»í•˜ê³  ê³µê°ì ì¸ ìƒë‹´ìì•¼."},
            {"role": "user", "content": user_input}
        ]
    )
    return response.choices[0].message.content

# ìŒì„± ì¸ì‹ í•¨ìˆ˜
def record_voice():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        st.info("ğŸ™ï¸ ë§í•´ì£¼ì„¸ìš”...")
        audio = recognizer.listen(source, phrase_time_limit=10)
        try:
            return recognizer.recognize_google(audio, language="ko-KR")
        except:
            st.warning("ìŒì„±ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return None

# TTS í•¨ìˆ˜
def speak(text):
    filename = f"voice_{uuid.uuid4().hex}.mp3"
    tts = gTTS(text=text, lang="ko")
    tts.save(filename)
    return filename

# 3. ì§ˆë¬¸ ì‘ë‹µ
if len(selected_questions) == 3:
    st.success("ì„ íƒì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.")
    for q in selected_questions:
        st.subheader(f"ğŸ—¨ï¸ {q}")
        if interface == "ğŸ“ í…ìŠ¤íŠ¸ ì¸í„°í˜ì´ìŠ¤":
            user_input = st.text_area("âœï¸ ë‹µë³€ì„ ì…ë ¥í•˜ì„¸ìš”:", key=q)
        else:
            if st.button(f"ğŸ™ï¸ '{q}'ì— ë‹µë³€ ë§í•˜ê¸°", key=f"btn_{q}"):
                user_input = record_voice()
                if user_input:
                    st.write(f"ğŸ§‘ ë‚´ ìŒì„± ì¸ì‹ ê²°ê³¼: **{user_input}**")
                else:
                    user_input = None
        if user_input:
            with st.spinner("GPTê°€ ì‘ë‹µ ì¤‘ì…ë‹ˆë‹¤..."):
                answer = ask_gpt(user_input)
            st.write("ğŸ¤– GPT ì‘ë‹µ:")
            st.info(answer)
            if interface == "ğŸ™ï¸ ìŒì„± ì¸í„°í˜ì´ìŠ¤":
                audio_file = speak(answer)
                st.audio(audio_file, format="audio/mp3")
            dialogue_data.append({
                "ì§ˆë¬¸": q,
                "ì‚¬ìš©ì ì‘ë‹µ": user_input,
                "GPT ì‘ë‹µ": answer,
                "ë°©ì‹": interface,
                "ì‹œê°„": datetime.datetime.now().isoformat()
            })

# 4. ì €ì¥ ë° ì„¤ë¬¸ ì´ë™
if dialogue_data and st.button("ğŸ’¾ ëŒ€í™” ì €ì¥ ë° ì„¤ë¬¸ì§€ë¡œ ì´ë™"):
    df = pd.DataFrame(dialogue_data)
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"dialogue_{timestamp}.csv"
    df.to_csv(filename, index=False)
    st.success(f"ëŒ€í™”ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤! íŒŒì¼ëª…: `{filename}`")
    st.markdown("ğŸ‘‰ [ğŸ“‹ ì„¤ë¬¸ì§€ ì‘ì„±í•˜ëŸ¬ ê°€ê¸°](https://forms.gle/aG7AhGAjLyMSGUvS8)", unsafe_allow_html=True)
else:
    st.warning("ëª¨ë“  ì§ˆë¬¸ì— ë‹µë³€ í›„ ì €ì¥ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
